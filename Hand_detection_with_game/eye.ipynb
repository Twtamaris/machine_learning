{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is eye[[335 305  61  61]\n",
      " [228 287  88  88]]\n",
      "This is eye[[227 287  89  89]]\n",
      "This is eye[[332 303  64  64]\n",
      " [224 286  90  90]]\n",
      "This is eye[[336 304  61  61]\n",
      " [229 286  87  87]]\n",
      "This is eye[[334 303  64  64]\n",
      " [229 283  91  91]]\n",
      "This is eye[[332 305  56  56]\n",
      " [232 285  89  89]]\n",
      "This is eye[[336 302  63  63]\n",
      " [229 287  86  86]]\n",
      "This is eye[[334 302  62  62]\n",
      " [228 283  92  92]]\n",
      "This is eye[[332 299  63  63]\n",
      " [232 281  93  93]]\n",
      "This is eye[[336 303  67  67]\n",
      " [232 286  89  89]]\n",
      "This is eye[[335 296  69  69]\n",
      " [233 284  92  92]]\n",
      "This is eye[[337 300  65  65]\n",
      " [232 285  88  88]]\n",
      "This is eye[[333 296  69  69]\n",
      " [235 284  90  90]]\n",
      "This is eye[[333 298  68  68]\n",
      " [232 285  88  88]]\n",
      "This is eye[[336 299  67  67]\n",
      " [230 287  84  84]]\n",
      "This is eye[[344 306  59  59]\n",
      " [231 285  86  86]]\n",
      "This is eye[[233 285  88  88]\n",
      " [339 301  64  64]]\n",
      "This is eye[[342 302  63  63]\n",
      " [233 286  84  84]]\n",
      "This is eye[[232 287  85  85]\n",
      " [328 286  86  86]]\n",
      "This is eye[[342 302  64  64]\n",
      " [229 285  88  88]]\n",
      "This is eye[[338 298  66  66]\n",
      " [237 286  82  82]]\n",
      "This is eye[[339 298  64  64]\n",
      " [234 281  90  90]]\n",
      "This is eye[[340 297  67  67]\n",
      " [238 286  85  85]]\n",
      "This is eye[[341 299  65  65]\n",
      " [233 284  88  88]]\n",
      "This is eye[[341 298  65  65]\n",
      " [231 282  90  90]]\n",
      "This is eye[[340 298  67  67]\n",
      " [236 285  86  86]]\n",
      "This is eye[[342 300  63  63]\n",
      " [236 286  86  86]]\n",
      "This is eye[[341 299  67  67]\n",
      " [236 283  89  89]]\n",
      "This is eye[[340 300  64  64]\n",
      " [237 292  78  78]]\n",
      "This is eye[[342 302  63  63]\n",
      " [238 290  79  79]]\n",
      "This is eye[[338 299  67  67]\n",
      " [240 292  78  78]]\n",
      "This is eye[[336 296  71  71]\n",
      " [240 297  74  74]]\n",
      "This is eye[[241 297  74  74]\n",
      " [334 296  73  73]]\n",
      "This is eye[[333 295  73  73]\n",
      " [240 297  73  73]]\n",
      "This is eye[[241 298  71  71]\n",
      " [330 294  75  75]]\n",
      "This is eye[[334 296  73  73]\n",
      " [240 297  74  74]]\n",
      "This is eye[[335 296  72  72]\n",
      " [242 297  74  74]]\n",
      "This is eye[[333 300  70  70]\n",
      " [238 299  76  76]]\n",
      "This is eye[[239 302  73  73]\n",
      " [335 299  71  71]]\n",
      "This is eye[[237 300  78  78]\n",
      " [336 303  66  66]]\n",
      "This is eye[[243 303  74  74]\n",
      " [334 303  69  69]]\n",
      "This is eye[[238 302  75  75]\n",
      " [331 299  74  74]]\n",
      "This is eye[[240 304  72  72]\n",
      " [327 296  80  80]]\n",
      "This is eye[[238 305  73  73]\n",
      " [335 303  69  69]]\n",
      "This is eye[[331 299  74  74]\n",
      " [239 302  76  76]]\n",
      "This is eye[[243 305  70  70]\n",
      " [334 304  67  67]]\n",
      "This is eye[[336 305  67  67]\n",
      " [239 301  77  77]]\n",
      "This is eye[[330 300  74  74]\n",
      " [241 304  72  72]]\n",
      "This is eye[[332 298  77  77]\n",
      " [239 299  78  78]]\n",
      "This is eye[[336 302  69  69]\n",
      " [241 299  77  77]]\n",
      "This is eye[[335 301  69  69]\n",
      " [237 297  82  82]]\n",
      "This is eye[[242 303  74  74]\n",
      " [334 299  72  72]]\n",
      "This is eye[[242 300  75  75]\n",
      " [337 303  68  68]]\n",
      "This is eye[[242 298  77  77]\n",
      " [334 300  71  71]]\n",
      "This is eye[[242 300  77  77]\n",
      " [334 299  72  72]]\n",
      "This is eye[[335 299  70  70]\n",
      " [241 300  77  77]]\n",
      "This is eye[[240 297  78  78]\n",
      " [329 296  76  76]]\n",
      "This is eye[[334 298  73  73]\n",
      " [239 296  80  80]]\n",
      "This is eye[[239 299  78  78]\n",
      " [329 292  80  80]]\n",
      "This is eye[[336 298  71  71]\n",
      " [241 297  80  80]]\n",
      "This is eye[[237 295  82  82]\n",
      " [332 294  76  76]]\n",
      "This is eye[[335 297  71  71]\n",
      " [242 298  76  76]]\n",
      "This is eye[[331 295  79  79]\n",
      " [241 296  79  79]]\n",
      "This is eye[[333 296  73  73]\n",
      " [239 296  78  78]]\n",
      "This is eye[[239 297  77  77]\n",
      " [329 293  80  80]]\n",
      "This is eye[[245 301  72  72]\n",
      " [330 292  79  79]]\n",
      "This is eye[[247 304  68  68]\n",
      " [335 296  72  72]]\n",
      "This is eye[[241 300  74  74]\n",
      " [331 296  76  76]]\n",
      "This is eye[[243 299  75  75]\n",
      " [332 293  77  77]]\n",
      "This is eye[[582  80  48  48]\n",
      " [334 294  75  75]\n",
      " [243 301  72  72]]\n",
      "This is eye[[241 299  75  75]\n",
      " [332 291  79  79]]\n",
      "This is eye[[241 302  69  69]\n",
      " [332 294  76  76]]\n",
      "This is eye[[332 292  77  77]\n",
      " [242 299  74  74]]\n",
      "This is eye[[241 300  71  71]\n",
      " [330 289  81  81]]\n",
      "This is eye[[247 302  68  68]\n",
      " [326 285  86  86]]\n",
      "This is eye[[243 298  73  73]\n",
      " [330 289  79  79]]\n",
      "This is eye[[243 298  73  73]\n",
      " [331 292  75  75]]\n",
      "This is eye[[241 296  74  74]\n",
      " [333 295  72  72]]\n",
      "This is eye[[242 297  74  74]\n",
      " [331 291  76  76]]\n",
      "This is eye[[239 298  72  72]\n",
      " [329 291  77  77]]\n",
      "This is eye[[239 295  75  75]\n",
      " [333 294  72  72]]\n",
      "This is eye[[240 295  75  75]\n",
      " [336 296  70  70]]\n",
      "This is eye[[238 294  79  79]\n",
      " [333 297  72  72]]\n",
      "This is eye[[242 298  72  72]\n",
      " [330 289  79  79]]\n",
      "This is eye[[244 298  72  72]\n",
      " [331 292  76  76]]\n",
      "This is eye[[242 296  74  74]\n",
      " [332 294  73  73]]\n",
      "This is eye[[238 297  74  74]\n",
      " [330 291  77  77]]\n",
      "This is eye[[245 300  71  71]\n",
      " [331 293  75  75]]\n",
      "This is eye[[245 301  70  70]\n",
      " [329 288  79  79]]\n",
      "This is eye[[239 297  74  74]\n",
      " [332 293  75  75]]\n",
      "This is eye[[244 298  74  74]\n",
      " [330 291  78  78]]\n",
      "This is eye[[246 302  69  69]\n",
      " [330 288  80  80]]\n",
      "This is eye[[243 298  73  73]\n",
      " [331 292  76  76]]\n",
      "This is eye[[244 297  74  74]\n",
      " [330 291  76  76]]\n",
      "This is eye[[236 295  78  78]\n",
      " [331 289  79  79]]\n",
      "This is eye[[242 299  72  72]\n",
      " [330 289  80  80]]\n",
      "This is eye[[333 294  74  74]\n",
      " [243 301  70  70]]\n",
      "This is eye[[242 298  74  74]\n",
      " [328 285  85  85]]\n",
      "This is eye[[577  77  50  50]\n",
      " [242 300  72  72]\n",
      " [329 292  79  79]]\n",
      "This is eye[[241 299  73  73]\n",
      " [329 289  83  83]]\n",
      "This is eye[[244 301  71  71]\n",
      " [334 295  72  72]]\n",
      "This is eye[[333 295  72  72]\n",
      " [240 297  76  76]]\n",
      "This is eye[[240 298  76  76]\n",
      " [331 293  77  77]]\n",
      "This is eye[[237 295  79  79]\n",
      " [332 294  76  76]]\n",
      "This is eye[[239 296  78  78]\n",
      " [330 296  75  75]]\n",
      "This is eye[[240 302  74  74]\n",
      " [329 296  75  75]]\n",
      "This is eye[[238 295  80  80]]\n",
      "This is eye[[239 295  84  84]]\n",
      "This is eye[[237 288  91  91]\n",
      " [325 287  84  84]]\n",
      "This is eye[[241 294  82  82]]\n",
      "This is eye()\n",
      "This is eye[[234 292  85  85]]\n",
      "This is eye[[235 286  92  92]]\n",
      "This is eye[[234 287  89  89]]\n",
      "This is eye[[232 288  84  84]]\n",
      "This is eye[[234 289  87  87]]\n",
      "This is eye[[241 293  84  84]\n",
      " [330 291  72  72]]\n",
      "This is eye[[238 289  85  85]\n",
      " [329 286  76  76]]\n",
      "This is eye[[248 299  74  74]\n",
      " [332 288  76  76]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade for eye detection\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Function to detect eyes in an image and return their positions\n",
    "def detect_eyes(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(30, 30))\n",
    "    print(f\"This is eye{eyes}\")\n",
    "    return eyes\n",
    "\n",
    "# Function to estimate the gaze direction based on the eye positions\n",
    "def estimate_gaze(eyes, image):\n",
    "    height, width, _ = image.shape\n",
    "    eye_centers = []\n",
    "    for (x, y, w, h) in eyes:\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        eye_centers.append((center_x, center_y))\n",
    "\n",
    "        # Draw bounding boxes around the eyes\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.circle(image, (center_x, center_y), 2, (0, 0, 255), 2)\n",
    "        \n",
    "    # Estimate the gaze direction based on the eye positions\n",
    "    # if len(eye_centers) == 2:\n",
    "    #     eye1_x, eye1_y = eye_centers[0]\n",
    "    #     eye2_x, eye2_y = eye_centers[1]\n",
    "\n",
    "    #     # Calculate the average of eye coordinates as the point of gaze\n",
    "    #     gaze_x = (eye1_x + eye2_x) // 2\n",
    "    #     gaze_y = (eye1_y + eye2_y) // 2\n",
    "\n",
    "    #     print(f\"User is looking at coordinates: ({gaze_x}, {gaze_y})\")\n",
    "\n",
    "    #     # Determine the gaze direction based on the differences in x and y coordinates\n",
    "    #     if gaze_y < height // 3:\n",
    "    #         # Look up\n",
    "    #         print(\"User is looking up\")\n",
    "    #         cv2.circle(image, (gaze_x, gaze_y), 10, (0, 0, 255), -1)\n",
    "    #     elif gaze_y > (2 * height) // 3:\n",
    "    #         # Look down\n",
    "    #         print(\"User is looking down\")\n",
    "    #         cv2.circle(image, (gaze_x, gaze_y), 10, (0, 0, 255), -1)\n",
    "    #     elif gaze_x < width // 3:\n",
    "    #         # Look left\n",
    "    #         print(\"User is looking left\")\n",
    "    #         cv2.circle(image, (gaze_x, gaze_y), 10, (0, 0, 255), -1)\n",
    "    #     elif gaze_x > (2 * width) // 3:\n",
    "    #         # Look right\n",
    "    #         print(\"User is looking right\")\n",
    "    #         cv2.circle(image, (gaze_x, gaze_y), 10, (0, 0, 255), -1)\n",
    "    #     else:\n",
    "    #         # Look straight ahead\n",
    "    #         print(\"User is looking straight ahead\")\n",
    "    #         cv2.circle(image, (gaze_x, gaze_y), 10, (0, 0, 255), -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Main loop to capture video from the webcam and detect eyes\n",
    "def main():\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip the frame horizontally for a mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Detect eyes in the frame\n",
    "        eyes = detect_eyes(frame)\n",
    "\n",
    "        # Estimate gaze direction and draw visualizations\n",
    "        output_frame = estimate_gaze(eyes, frame)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Eye Detection', output_frame)\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close the OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "bottom_middle\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "bottom_middle\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('eye_model.h5')\n",
    "folders = ['bottom_left', 'bottom_right', 'bottom_middle', 'top_left', 'top_right', 'top_middle', 'left_middle', 'right_middle']\n",
    "\n",
    "\n",
    "\n",
    "# Load your pre-trained CNN model\n",
    "\n",
    "# Define the desired dimensions\n",
    "desired_width = 250\n",
    "desired_height = 50\n",
    "\n",
    "# Initialize the webcam\n",
    "video_capture = cv2.VideoCapture(0)  # 0 represents the default webcam device\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    # frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Define the ROI coordinates for the eye portion\n",
    "    eye_x = 100\n",
    "    eye_y = 100\n",
    "    eye_width = 150\n",
    "    eye_height = 50\n",
    "\n",
    "    # Extract the eye ROI from the frame\n",
    "    eye_roi = frame[eye_y:eye_y+eye_height, eye_x:eye_x+eye_width]\n",
    "\n",
    "    # Resize the ROI to match the desired dimensions\n",
    "    resized_roi = cv2.resize(eye_roi, (desired_width, desired_height))\n",
    "\n",
    "    # Convert the ROI to RGB format\n",
    "    resized_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the ROI to numpy array\n",
    "    resized_roi = np.asarray(resized_roi)\n",
    "\n",
    "    # Expand dimensions to match the input shape of your CNN model\n",
    "    resized_roi = np.expand_dims(resized_roi, axis=0)\n",
    "\n",
    "    # Normalize pixel values\n",
    "    resized_roi = resized_roi / 255.0\n",
    "\n",
    "    # Pass the preprocessed ROI through your CNN model for prediction\n",
    "    predictions = model.predict(resized_roi)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Display the predicted class\n",
    "    print(folders[predicted_class[0]])\n",
    "    # Display the frame with overlays or visual indicators of person detection\n",
    "    cv2.imshow('Eye Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\machine_learning\\Hand_detection_with_game\\eye.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m# print(predicted_class)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mrectangle(frame, (eye_x, eye_y), (eye_x\u001b[39m+\u001b[39meye_width, eye_y\u001b[39m+\u001b[39meye_height), (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mputText(frame, folders[predicted_class[\u001b[39m0\u001b[39;49m]], (eye_x, eye_y\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m), cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m0.9\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39m# if predicted_class == 0:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39m#     print(\"bottom left corner\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# if predicted_class == 1:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Display the frame with overlays or visual indicators of eye detection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/machine_learning/Hand_detection_with_game/eye.ipynb#W2sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mflip(frame, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "model = load_model('eye_model_by_saurabey.h5')\n",
    "folders = ['bottom_left', 'bottom_right', 'bottom_middle', 'top_left', 'top_right', 'top_middle', 'left_middle', 'right_middle']\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Load your pre-trained CNN model\n",
    "def detect_eyes(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(30, 30))\n",
    "    return eyes\n",
    "\n",
    "\n",
    "# Define the desired dimensions\n",
    "desired_width = 250\n",
    "desired_height = 50\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "folder_path = 'eyes_pattern'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Initialize the webcam\n",
    "video_capture = cv2.VideoCapture(0)  # 0 represents the default webcam device\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = video_capture.read()\n",
    "    eyes = detect_eyes(frame)\n",
    "\n",
    "    if len(eyes) >= 2:\n",
    "        (eye_1x, eye_1y, eye_1width, eye_1height), (eye_2x, eye_2y, eye_2width, eye_2height) = eyes[:2]\n",
    "        eye_x = min(eye_1x, eye_2x)\n",
    "        eye_y = min(eye_1y, eye_2y)\n",
    "        eye_width = abs(eye_1x - eye_2x) + max(eye_1width, eye_2width)\n",
    "        eye_height = abs(eye_1y - eye_2y) + max(eye_1height, eye_2height)\n",
    "        \n",
    "        eye_roi = frame[eye_y:eye_y+eye_height, eye_x:eye_x+eye_width]\n",
    "\n",
    "        # Resize the ROI to match the desired dimensions\n",
    "        resized_roi = cv2.resize(eye_roi, (desired_width, desired_height))\n",
    "\n",
    "        # Convert the ROI to RGB format\n",
    "        resized_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert the ROI to numpy array\n",
    "        resized_roi = np.asarray(resized_roi)\n",
    "\n",
    "        # Expand dimensions to match the input shape of your CNN model\n",
    "        resized_roi = np.expand_dims(resized_roi, axis=0)\n",
    "\n",
    "        # Normalize pixel values\n",
    "        resized_roi = resized_roi / 255.0\n",
    "\n",
    "        # Pass the preprocessed ROI through your CNN model for prediction\n",
    "        predictions = model.predict(resized_roi)\n",
    "        predicted_class = np.argmax(predictions, axis=1)\n",
    "        # print(predicted_class)\n",
    "        frame = cv2.rectangle(frame, (eye_x, eye_y), (eye_x+eye_width, eye_y+eye_height), (0, 255, 0), 2)\n",
    "        frame = cv2.putText(frame, folders[predicted_class[0]], (eye_x, eye_y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        # if predicted_class == 0:\n",
    "        #     print(\"bottom left corner\")\n",
    "        # if predicted_class == 1:\n",
    "        #     print(\"bottom right corner\")\n",
    "        # # if predicted_class == 2:\n",
    "        # #     print(\"bottom middle\")\n",
    "        # # if predicted_class == 3:\n",
    "        # #     print(\"top left corner\")\n",
    "        # # if predicted_class == 4:\n",
    "        # #     print(\"top right corner\")\n",
    "        # # if predicted_class == 5:\n",
    "        # #     print(\"top middle\")\n",
    "        # # if predicted_class == 6:\n",
    "        # #     print(\"left middle\")\n",
    "        # # if predicted_class == 7:\n",
    "        # #     print(\"right middle\")\n",
    "\n",
    "        \n",
    "\n",
    "    # Display the frame with overlays or visual indicators of eye detection\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2.imshow('Eye Detection', frame)\n",
    "\n",
    "    # Add a small delay to reduce processing load\n",
    "    # time.sleep(0.01)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the frame in the \"eyes_pattern\" folder\n",
    "frame_count += 1\n",
    "filename = os.path.join(folder_path, f'frame_{frame_count}.jpg')\n",
    "cv2.imwrite(filename, eye_roi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
